{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Applications\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import necessary libraries\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar100\n",
    "from keras import regularizers, optimizers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      " 69918720/169001437 [===========>..................] - ETA: 50s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8892bc45d867>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Load CIFAR-10 dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcifar100\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Applications\\Anaconda\\lib\\site-packages\\keras\\datasets\\cifar100.py\u001b[0m in \u001b[0;36mload_data\u001b[1;34m(label_mode)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mdirname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'cifar-100-python'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0morigin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muntar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mfpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Applications\\Anaconda\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget_file\u001b[1;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m                 \u001b[0murlretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdl_progress\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mURLError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrno\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Applications\\Anaconda\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m                 \u001b[0mblock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    278\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Applications\\Anaconda\\lib\\http\\client.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    447\u001b[0m             \u001b[1;31m# Amount is given, implement using readinto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m             \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Applications\\Anaconda\\lib\\http\\client.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    491\u001b[0m         \u001b[1;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[1;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Applications\\Anaconda\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Applications\\Anaconda\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1007\u001b[0m                   \u001b[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1008\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1009\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1010\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1011\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Applications\\Anaconda\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m    869\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Read on closed or unwrapped SSL socket.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    872\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Applications\\Anaconda\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m    629\u001b[0m         \"\"\"\n\u001b[0;32m    630\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 631\u001b[1;33m             \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    632\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Load CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert train and test images to float values with a range from 0 to 1\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Number of classes in CIFAR-10\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Change class labels to categorical values\n",
    "y_train = np_utils.to_categorical(y_train,num_classes)\n",
    "y_test = np_utils.to_categorical(y_test,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Base Resolution of 32 x 32\n",
    "baseRes = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initiate a  sequential Keras model\n",
    "model = Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create convolution layer 1 with 32 filters\n",
    "model.add(Conv2D(baseRes,\n",
    "                 (3,3),\n",
    "                 padding='same', \n",
    "                 activation='relu',\n",
    "                 input_shape=x_train.shape[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create convolution layer 2 with 32 filters\n",
    "model.add(Conv2D(baseRes,\n",
    "                 (3,3),\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(1e-4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add a max pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add a dropout layer\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create convolution layer 3 with 64 filters\n",
    "model.add(Conv2D(2*baseRes,\n",
    "                 (3,3),\n",
    "                 padding='same',\n",
    "                 activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create convolution layer 4 with 64 filters\n",
    "model.add(Conv2D(2*baseRes,\n",
    "                 (3,3),\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(1e-4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add a max pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add a droupout layer\n",
    "model.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create convolution layer 5 with 128 filters\n",
    "model.add(Conv2D(4*baseRes, \n",
    "                 (3,3), \n",
    "                 padding='same', \n",
    "                 activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create convolution layer 6 with 128 filters\n",
    "model.add(Conv2D(4*baseRes, \n",
    "                 (3,3), \n",
    "                 padding='same', \n",
    "                 activation='relu', \n",
    "                 kernel_regularizer=regularizers.l2(1e-4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add a max pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add a dropout layer\n",
    "model.add(Dropout(0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add a layer to flatten the values\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add a dense layer with softmax activation to get the output for the 10 classes\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 309,290\n",
      "Trainable params: 308,394\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Summarize model structure\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data augmentation\n",
    "This step creates multiple copies of the same image that have the following operations performed on them\n",
    "1. Shift horizontally\n",
    "2. Shift vertically\n",
    "3. Rotate\n",
    "4. Invert horizontally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    "    )\n",
    "\n",
    "#Data generator\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Applications\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "#Importing tensorboard and configuring a directory\n",
    "from keras.callbacks import TensorBoard\n",
    "tensorboard_1 = TensorBoard(log_dir=\"D:\\Data\\Tensorboard\\model_base_final2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/100\n",
      "781/781 [==============================] - 92s 118ms/step - loss: 2.1108 - acc: 0.3471 - val_loss: 1.7137 - val_acc: 0.4412\n",
      "Epoch 2/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 1.6090 - acc: 0.4805 - val_loss: 1.7705 - val_acc: 0.4938\n",
      "Epoch 3/100\n",
      "781/781 [==============================] - 89s 114ms/step - loss: 1.4239 - acc: 0.5462 - val_loss: 1.3850 - val_acc: 0.5704\n",
      "Epoch 4/100\n",
      "781/781 [==============================] - 89s 113ms/step - loss: 1.3563 - acc: 0.5811 - val_loss: 1.2503 - val_acc: 0.6117\n",
      "Epoch 5/100\n",
      "781/781 [==============================] - 89s 114ms/step - loss: 1.2793 - acc: 0.6063 - val_loss: 1.1209 - val_acc: 0.6322\n",
      "Epoch 6/100\n",
      "781/781 [==============================] - 89s 114ms/step - loss: 1.2097 - acc: 0.6261 - val_loss: 1.0243 - val_acc: 0.6529\n",
      "Epoch 7/100\n",
      "781/781 [==============================] - 88s 113ms/step - loss: 1.1650 - acc: 0.6434 - val_loss: 1.2209 - val_acc: 0.6296\n",
      "Epoch 8/100\n",
      "781/781 [==============================] - 88s 113ms/step - loss: 1.1251 - acc: 0.6522 - val_loss: 1.1167 - val_acc: 0.6659\n",
      "Epoch 9/100\n",
      "781/781 [==============================] - 89s 114ms/step - loss: 1.1063 - acc: 0.6616 - val_loss: 1.0886 - val_acc: 0.6700\n",
      "Epoch 10/100\n",
      "781/781 [==============================] - 89s 114ms/step - loss: 1.0892 - acc: 0.6668 - val_loss: 1.0592 - val_acc: 0.6619\n",
      "Epoch 11/100\n",
      "781/781 [==============================] - 89s 114ms/step - loss: 1.0802 - acc: 0.6758 - val_loss: 1.0616 - val_acc: 0.6804\n",
      "Epoch 12/100\n",
      "781/781 [==============================] - 89s 114ms/step - loss: 1.0519 - acc: 0.6830 - val_loss: 0.9788 - val_acc: 0.6878\n",
      "Epoch 13/100\n",
      "781/781 [==============================] - 89s 114ms/step - loss: 1.0222 - acc: 0.6908 - val_loss: 1.2311 - val_acc: 0.6721\n",
      "Epoch 14/100\n",
      "781/781 [==============================] - 89s 114ms/step - loss: 0.9989 - acc: 0.6950 - val_loss: 1.0398 - val_acc: 0.6822\n",
      "Epoch 15/100\n",
      "781/781 [==============================] - 89s 114ms/step - loss: 0.9963 - acc: 0.7002 - val_loss: 0.8690 - val_acc: 0.7303\n",
      "Epoch 16/100\n",
      "781/781 [==============================] - 89s 114ms/step - loss: 0.9656 - acc: 0.7060 - val_loss: 0.8688 - val_acc: 0.7250\n",
      "Epoch 17/100\n",
      "781/781 [==============================] - 89s 114ms/step - loss: 0.9509 - acc: 0.7134 - val_loss: 0.9161 - val_acc: 0.7173\n",
      "Epoch 18/100\n",
      "781/781 [==============================] - 89s 114ms/step - loss: 0.9412 - acc: 0.7161 - val_loss: 0.8903 - val_acc: 0.7230\n",
      "Epoch 19/100\n",
      "781/781 [==============================] - 89s 114ms/step - loss: 0.9193 - acc: 0.7211 - val_loss: 0.8539 - val_acc: 0.7351\n",
      "Epoch 20/100\n",
      "781/781 [==============================] - 89s 114ms/step - loss: 0.9078 - acc: 0.7265 - val_loss: 0.8961 - val_acc: 0.7253\n",
      "Epoch 21/100\n",
      "781/781 [==============================] - 91s 116ms/step - loss: 0.9219 - acc: 0.7253 - val_loss: 0.8950 - val_acc: 0.7184\n",
      "Epoch 22/100\n",
      "781/781 [==============================] - 91s 117ms/step - loss: 0.8980 - acc: 0.7277 - val_loss: 0.8268 - val_acc: 0.7402\n",
      "Epoch 23/100\n",
      "781/781 [==============================] - 89s 114ms/step - loss: 0.8922 - acc: 0.7316 - val_loss: 0.8061 - val_acc: 0.7489\n",
      "Epoch 24/100\n",
      "781/781 [==============================] - 89s 114ms/step - loss: 0.8850 - acc: 0.7369 - val_loss: 0.8136 - val_acc: 0.7469\n",
      "Epoch 25/100\n",
      "781/781 [==============================] - 89s 114ms/step - loss: 0.8697 - acc: 0.7360 - val_loss: 0.8675 - val_acc: 0.7447\n",
      "Epoch 26/100\n",
      "781/781 [==============================] - 89s 114ms/step - loss: 0.8601 - acc: 0.7410 - val_loss: 0.7763 - val_acc: 0.7586\n",
      "Epoch 27/100\n",
      "781/781 [==============================] - 89s 114ms/step - loss: 0.8773 - acc: 0.7407 - val_loss: 0.7683 - val_acc: 0.7637\n",
      "Epoch 28/100\n",
      "781/781 [==============================] - 89s 114ms/step - loss: 0.8361 - acc: 0.7459 - val_loss: 0.8403 - val_acc: 0.7428\n",
      "Epoch 29/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.8266 - acc: 0.7509 - val_loss: 0.7811 - val_acc: 0.7637\n",
      "Epoch 30/100\n",
      "781/781 [==============================] - 89s 115ms/step - loss: 0.8219 - acc: 0.7478 - val_loss: 0.7252 - val_acc: 0.7703\n",
      "Epoch 31/100\n",
      "781/781 [==============================] - 89s 114ms/step - loss: 0.8025 - acc: 0.7547 - val_loss: 0.8268 - val_acc: 0.7586\n",
      "Epoch 32/100\n",
      "781/781 [==============================] - 89s 114ms/step - loss: 0.7997 - acc: 0.7546 - val_loss: 0.9795 - val_acc: 0.7217\n",
      "Epoch 33/100\n",
      "781/781 [==============================] - 89s 114ms/step - loss: 0.7924 - acc: 0.7572 - val_loss: 0.7667 - val_acc: 0.7620\n",
      "Epoch 34/100\n",
      "781/781 [==============================] - 89s 114ms/step - loss: 0.7802 - acc: 0.7605 - val_loss: 0.7616 - val_acc: 0.7704\n",
      "Epoch 35/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.7721 - acc: 0.7596 - val_loss: 0.8334 - val_acc: 0.7450\n",
      "Epoch 36/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.7607 - acc: 0.7646 - val_loss: 0.7197 - val_acc: 0.7797\n",
      "Epoch 37/100\n",
      "781/781 [==============================] - 89s 115ms/step - loss: 0.7488 - acc: 0.7642 - val_loss: 0.8234 - val_acc: 0.7547\n",
      "Epoch 38/100\n",
      "781/781 [==============================] - 89s 114ms/step - loss: 0.7438 - acc: 0.7654 - val_loss: 0.7345 - val_acc: 0.7749\n",
      "Epoch 39/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.7417 - acc: 0.7683 - val_loss: 0.8682 - val_acc: 0.7421\n",
      "Epoch 40/100\n",
      "781/781 [==============================] - 89s 114ms/step - loss: 0.7295 - acc: 0.7731 - val_loss: 0.7218 - val_acc: 0.7753\n",
      "Epoch 41/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.7260 - acc: 0.7718 - val_loss: 0.6775 - val_acc: 0.7937\n",
      "Epoch 42/100\n",
      "781/781 [==============================] - 90s 116ms/step - loss: 0.7197 - acc: 0.7721 - val_loss: 0.7050 - val_acc: 0.7874\n",
      "Epoch 43/100\n",
      "781/781 [==============================] - 91s 117ms/step - loss: 0.7213 - acc: 0.7728 - val_loss: 0.6808 - val_acc: 0.7934\n",
      "Epoch 44/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.7151 - acc: 0.7774 - val_loss: 0.8581 - val_acc: 0.7495\n",
      "Epoch 45/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.7039 - acc: 0.7792 - val_loss: 0.6864 - val_acc: 0.7918\n",
      "Epoch 46/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.7056 - acc: 0.7778 - val_loss: 0.6953 - val_acc: 0.7872\n",
      "Epoch 47/100\n",
      "781/781 [==============================] - 93s 119ms/step - loss: 0.6946 - acc: 0.7801 - val_loss: 0.6685 - val_acc: 0.7915\n",
      "Epoch 48/100\n",
      "781/781 [==============================] - 91s 116ms/step - loss: 0.6959 - acc: 0.7823 - val_loss: 0.6876 - val_acc: 0.7908\n",
      "Epoch 49/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.6965 - acc: 0.7797 - val_loss: 0.6846 - val_acc: 0.7928\n",
      "Epoch 50/100\n",
      "781/781 [==============================] - 89s 114ms/step - loss: 0.6852 - acc: 0.7859 - val_loss: 0.6750 - val_acc: 0.7947\n",
      "Epoch 51/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.6799 - acc: 0.7874 - val_loss: 0.6364 - val_acc: 0.8074\n",
      "Epoch 52/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.6818 - acc: 0.7855 - val_loss: 0.6909 - val_acc: 0.7912\n",
      "Epoch 53/100\n",
      "781/781 [==============================] - 90s 116ms/step - loss: 0.6756 - acc: 0.7884 - val_loss: 0.6791 - val_acc: 0.7976\n",
      "Epoch 54/100\n",
      "781/781 [==============================] - 89s 114ms/step - loss: 0.6738 - acc: 0.7875 - val_loss: 0.7147 - val_acc: 0.7822\n",
      "Epoch 55/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.6691 - acc: 0.7899 - val_loss: 0.6876 - val_acc: 0.7915\n",
      "Epoch 56/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.6705 - acc: 0.7885 - val_loss: 0.6987 - val_acc: 0.7895\n",
      "Epoch 57/100\n",
      "781/781 [==============================] - 89s 114ms/step - loss: 0.6622 - acc: 0.7921 - val_loss: 0.6482 - val_acc: 0.8012\n",
      "Epoch 58/100\n",
      "781/781 [==============================] - 89s 115ms/step - loss: 0.6628 - acc: 0.7926 - val_loss: 0.6746 - val_acc: 0.7962\n",
      "Epoch 59/100\n",
      "781/781 [==============================] - 91s 116ms/step - loss: 0.6572 - acc: 0.7942 - val_loss: 0.6697 - val_acc: 0.7983\n",
      "Epoch 60/100\n",
      "781/781 [==============================] - 91s 116ms/step - loss: 0.6569 - acc: 0.7947 - val_loss: 0.6978 - val_acc: 0.7930\n",
      "Epoch 61/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.6502 - acc: 0.7968 - val_loss: 0.6303 - val_acc: 0.8119\n",
      "Epoch 62/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.6541 - acc: 0.7964 - val_loss: 0.6426 - val_acc: 0.8082\n",
      "Epoch 63/100\n",
      "781/781 [==============================] - 91s 117ms/step - loss: 0.6555 - acc: 0.7944 - val_loss: 0.6115 - val_acc: 0.8135\n",
      "Epoch 64/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.6504 - acc: 0.7958 - val_loss: 0.6934 - val_acc: 0.7953\n",
      "Epoch 65/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.6482 - acc: 0.7956 - val_loss: 0.6222 - val_acc: 0.8133\n",
      "Epoch 66/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.6468 - acc: 0.7981 - val_loss: 0.7438 - val_acc: 0.7769\n",
      "Epoch 67/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.6466 - acc: 0.7983 - val_loss: 0.7285 - val_acc: 0.7858\n",
      "Epoch 68/100\n",
      "781/781 [==============================] - 91s 116ms/step - loss: 0.6396 - acc: 0.8000 - val_loss: 0.7275 - val_acc: 0.7854\n",
      "Epoch 69/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.6362 - acc: 0.8011 - val_loss: 0.6494 - val_acc: 0.8026\n",
      "Epoch 70/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.6380 - acc: 0.8015 - val_loss: 0.6389 - val_acc: 0.8100\n",
      "Epoch 71/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.6373 - acc: 0.8003 - val_loss: 0.6593 - val_acc: 0.8048\n",
      "Epoch 72/100\n",
      "781/781 [==============================] - 90s 116ms/step - loss: 0.6295 - acc: 0.8019 - val_loss: 0.6507 - val_acc: 0.8008\n",
      "Epoch 73/100\n",
      "781/781 [==============================] - 90s 116ms/step - loss: 0.6374 - acc: 0.8026 - val_loss: 0.7355 - val_acc: 0.7840\n",
      "Epoch 74/100\n",
      "781/781 [==============================] - 90s 116ms/step - loss: 0.6327 - acc: 0.8014 - val_loss: 0.6494 - val_acc: 0.8114\n",
      "Epoch 75/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.6248 - acc: 0.8057 - val_loss: 0.6403 - val_acc: 0.8087\n",
      "Epoch 76/100\n",
      "781/781 [==============================] - 90s 116ms/step - loss: 0.6253 - acc: 0.8044 - val_loss: 0.6474 - val_acc: 0.8080\n",
      "Epoch 77/100\n",
      "781/781 [==============================] - 91s 116ms/step - loss: 0.6238 - acc: 0.8049 - val_loss: 0.5928 - val_acc: 0.8220\n",
      "Epoch 78/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.6224 - acc: 0.8046 - val_loss: 0.5837 - val_acc: 0.8260\n",
      "Epoch 79/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.6201 - acc: 0.8076 - val_loss: 0.6112 - val_acc: 0.8167\n",
      "Epoch 80/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.6250 - acc: 0.8051 - val_loss: 0.6420 - val_acc: 0.8078\n",
      "Epoch 81/100\n",
      "781/781 [==============================] - 90s 116ms/step - loss: 0.6176 - acc: 0.8078 - val_loss: 0.6365 - val_acc: 0.8088\n",
      "Epoch 82/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.6183 - acc: 0.8075 - val_loss: 0.6416 - val_acc: 0.8066\n",
      "Epoch 83/100\n",
      "781/781 [==============================] - 91s 116ms/step - loss: 0.6135 - acc: 0.8097 - val_loss: 0.6210 - val_acc: 0.8142\n",
      "Epoch 84/100\n",
      "781/781 [==============================] - 89s 114ms/step - loss: 0.6129 - acc: 0.8090 - val_loss: 0.6134 - val_acc: 0.8139\n",
      "Epoch 85/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.6115 - acc: 0.8084 - val_loss: 0.6439 - val_acc: 0.8084\n",
      "Epoch 86/100\n",
      "781/781 [==============================] - 90s 116ms/step - loss: 0.6117 - acc: 0.8105 - val_loss: 0.6129 - val_acc: 0.8176\n",
      "Epoch 87/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.6112 - acc: 0.8100 - val_loss: 0.6341 - val_acc: 0.8139\n",
      "Epoch 88/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.6128 - acc: 0.8094 - val_loss: 0.6071 - val_acc: 0.8178\n",
      "Epoch 89/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.6017 - acc: 0.8134 - val_loss: 0.6273 - val_acc: 0.8113\n",
      "Epoch 90/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.6107 - acc: 0.8111 - val_loss: 0.6271 - val_acc: 0.8131\n",
      "Epoch 91/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.6077 - acc: 0.8111 - val_loss: 0.5905 - val_acc: 0.8239\n",
      "Epoch 92/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.6151 - acc: 0.8104 - val_loss: 0.6410 - val_acc: 0.8091\n",
      "Epoch 93/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.6052 - acc: 0.8116 - val_loss: 0.6239 - val_acc: 0.8186\n",
      "Epoch 94/100\n",
      "781/781 [==============================] - 91s 116ms/step - loss: 0.6035 - acc: 0.8115 - val_loss: 0.6854 - val_acc: 0.7992\n",
      "Epoch 95/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.6031 - acc: 0.8126 - val_loss: 0.6061 - val_acc: 0.8215\n",
      "Epoch 96/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.5988 - acc: 0.8132 - val_loss: 0.5964 - val_acc: 0.8238\n",
      "Epoch 97/100\n",
      "781/781 [==============================] - 90s 116ms/step - loss: 0.6005 - acc: 0.8140 - val_loss: 0.6136 - val_acc: 0.8182\n",
      "Epoch 98/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.5974 - acc: 0.8152 - val_loss: 0.6135 - val_acc: 0.8187\n",
      "Epoch 99/100\n",
      "781/781 [==============================] - 90s 115ms/step - loss: 0.6005 - acc: 0.8142 - val_loss: 0.6136 - val_acc: 0.8230\n",
      "Epoch 100/100\n",
      "781/781 [==============================] - 92s 118ms/step - loss: 0.5982 - acc: 0.8153 - val_loss: 0.6156 - val_acc: 0.8167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c866226cf8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training\n",
    "batch_size = 64\n",
    "epochs=25\n",
    "\n",
    "#Define optimizer\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.0005,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                    epochs=4*epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test,y_test),\n",
    "                    callbacks=[tensorboard_1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 6s 593us/step\n",
      "\n",
      "Test result: 83.890 loss: 0.545\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
    "print('\\nTest result: %.3f loss: %.3f' % (scores[1]*100,scores[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
